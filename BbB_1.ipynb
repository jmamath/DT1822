{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BbB_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBw4VzYit4af",
        "colab_type": "text"
      },
      "source": [
        "#Downloading required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhWibY0YNzjn",
        "colab_type": "code",
        "outputId": "a81a34c9-c10f-4db3-bc68-8b08d08bfe88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "### Installing required packages\n",
        "!pip install pyro-ppl==0.3.2\n",
        "!pip install pycuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyro-ppl==0.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/df/9d49d1fa8d4e47d473c801bf22f9d2a433a0e61c609bedc5681ae0e22e76/pyro-ppl-0.3.2.tar.gz (230kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 16.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20kB 4.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 40kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 61kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 71kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 81kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 102kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 112kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 122kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 133kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 143kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 153kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 163kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 174kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 184kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 194kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 204kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 215kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 225kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl==0.3.2) (0.5.5)\n",
            "Requirement already satisfied: graphviz>=0.8 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl==0.3.2) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl==0.3.2) (1.16.4)\n",
            "Collecting opt_einsum>=2.3.2 (from pyro-ppl==0.3.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/d6/44792ec668bcda7d91913c75237314e688f70415ab2acd7172c845f0b24f/opt_einsum-2.3.2.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 18.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl==0.3.2) (1.12.0)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl==0.3.2) (1.1.0)\n",
            "Requirement already satisfied: tqdm>=4.28 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl==0.3.2) (4.28.1)\n",
            "Building wheels for collected packages: pyro-ppl, opt-einsum\n",
            "  Building wheel for pyro-ppl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/2f/21/9f840307c05be374f101b0e4aee2db0596437fe2ade0334c2f\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/3e/a3/b351fae0cbf15373c2136a54a70f43fea5fe91d8168a5faaa4\n",
            "Successfully built pyro-ppl opt-einsum\n",
            "Installing collected packages: opt-einsum, pyro-ppl\n",
            "Successfully installed opt-einsum-2.3.2 pyro-ppl-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4DuPTenNpoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import pyro\n",
        "from pyro.distributions import Normal, Delta\n",
        "from diag_normal_mixture import MixtureOfDiagNormals\n",
        "from pyro.infer import  SVI , Trace_ELBO , EmpiricalMarginal, TracePredictive\n",
        "from pyro.optim import Adam\n",
        "from torch.distributions import constraints\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "import fileinput\n",
        "import pycuda.driver as cuda\n",
        "import requests\n",
        "from functools import partial\n",
        "cuda.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY5E0VMdt8s_",
        "colab_type": "text"
      },
      "source": [
        "#Loading libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gHPonDmuDT_",
        "colab_type": "text"
      },
      "source": [
        "#Loading data\n",
        "\n",
        "This is mostly boiler plate code, except for the boston and yacht datasets, every data is read directly from the source on github. For the case of boston and yacht datasets, we download them locally to fix some issues concerning the separator between each columns.\n",
        "\n",
        "Each dataset call is then associated to a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxQMdAP4N6D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Loading data \n",
        "\"\"\" \n",
        "This is mostly boiler plate code, except the boston and yacht datasets, every data is read directly from the \n",
        "source on github. For the case of boston and yacht datasets, we download them locally to fix some issues concerning\n",
        "the separator between each columns.\n",
        "\"\"\"\n",
        "boston_url = \"https://media.githubusercontent.com/media/probabilisticai/dt8122/master/datasets/boston_housing.txt\"\n",
        "concrete_url = \"https://media.githubusercontent.com/media/probabilisticai/dt8122/master/datasets/concrete.txt\"\n",
        "energy_url = \"https://media.githubusercontent.com/media/probabilisticai/dt8122/master/datasets/energy_heating_load.txt\"\n",
        "kin8_url = \"https://media.githubusercontent.com/media/probabilisticai/dt8122/master/datasets/kin8nm.txt\"\n",
        "naval_url = \"https://media.githubusercontent.com/media/probabilisticai/dt8122/master/datasets/naval_compressor_decay.txt\"\n",
        "power_url = \"https://media.githubusercontent.com/media/probabilisticai/dt8122/master/datasets/power.txt\"\n",
        "protein_url = \"https://media.githubusercontent.com/media/probabilisticai/dt8122/master/datasets/protein.txt\"\n",
        "wine_url = \"https://media.githubusercontent.com/media/probabilisticai/dt8122/master/datasets/wine.txt\"\n",
        "yacht_url = \"https://media.githubusercontent.com/media/probabilisticai/dt8122/master/datasets/yacht.txt\"\n",
        "year_prediction_url = \"https://media.githubusercontent.com/media/probabilisticai/dt8122/master/datasets/year_prediction_msd.txt\"\n",
        "\n",
        "\n",
        "def boston():\n",
        "  r = requests.get(boston_url)\n",
        "  with open('/content/boston.txt', 'wb') as f:  \n",
        "    f.write(r.content)\n",
        "  with fileinput.FileInput(\"boston.txt\", inplace=True, backup='.bak') as file:\n",
        "    for line in file:\n",
        "        print(line.replace(\"   \", \" \"), end='')\n",
        "  bos = [str(i) for i in range(14)]\n",
        "  boston = pd.read_csv('boston.txt', sep=\"  | \",names = bos, header=None)\n",
        "  print(\"Boston dataset - {} examples - 14 columns\".format(len(boston)))\n",
        "  print(\"Number of Nan :{}\".format(boston.isna().sum().sum())) \n",
        "  return boston, 14\n",
        "\n",
        "def concrete():\n",
        "  conc = [str(i) for i in range(9)]\n",
        "  concrete = pd.read_csv(concrete_url, sep=\" |\\t\",names = conc, header=None)\n",
        "  print(\"Concrete dataset - {} examples - 9 columns\".format(len(concrete)))\n",
        "  print(\"Number of Nan :{}\".format(concrete.isna().sum().sum())) \n",
        "  return concrete, 9\n",
        "\n",
        "def energy():  \n",
        "  ener = [str(i) for i in range(9)]\n",
        "  energy = pd.read_csv(energy_url, sep=\" |\\t\",names = ener, header=None)\n",
        "  print(\"Energy dataset - {} examples - 9 columns\".format(len(energy)))\n",
        "  print(\"Number of Nan :{}\".format(energy.isna().sum().sum())) \n",
        "  return energy, 9\n",
        "\n",
        "def kin8nm():\n",
        "  kin8 = [str(i) for i in range(9)]\n",
        "  kin8nm = pd.read_csv(kin8_url, sep=\"   |  \",names = kin8, header=None)\n",
        "  print(\"Kin8nm dataset - {} examples - 10 columns\".format(len(kin8nm)))\n",
        "  print(\"Number of Nan :{}\".format(kin8nm.isna().sum().sum())) \n",
        "  return kin8nm, 9\n",
        "\n",
        "def naval():\n",
        "  nav = [str(i) for i in range(17)]\n",
        "  naval = pd.read_csv(naval_url, sep=\" |\\t\", names = nav, header=None)\n",
        "  print(\"Naval dataset - {} examples - 17 columns\".format(len(naval)))\n",
        "  print(\"Number of Nan :{}\".format(naval.isna().sum().sum())) \n",
        "  return naval, 17\n",
        "\n",
        "def power():\n",
        "  pow = [str(i) for i in range(5)]\n",
        "  power = pd.read_csv(power_url, sep=\" |\\t\", names = pow, header=None)\n",
        "  print(\"Power dataset - {} examples - 5 columns\".format(len(power)))\n",
        "  print(\"Number of Nan :{}\".format(power.isna().sum().sum())) \n",
        "  return power, 5\n",
        "\n",
        "def protein():\n",
        "  prot = [str(i) for i in range(10)]\n",
        "  protein = pd.read_csv(protein_url, sep=\" |\\t\", names = prot, header=None)\n",
        "  print(\"Protein dataset - {} examples - 10 columns\".format(len(protein)))\n",
        "  print(\"Number of Nan :{}\".format(protein.isna().sum().sum())) \n",
        "  return protein, 10\n",
        "\n",
        "def wine():\n",
        "  w = [str(i) for i in range(12)]\n",
        "  wine = pd.read_csv(wine_url, sep=\" |\\t\", names = w, header=None)\n",
        "  print(\"Wine dataset - {} examples - 12 columns\".format(len(wine)))\n",
        "  print(\"Number of Nan :{}\".format(wine.isna().sum().sum())) \n",
        "  return wine, 12\n",
        "\n",
        "def yacht(): \n",
        "  r = requests.get(yacht_url)\n",
        "  with open('/content/yacht.txt', 'wb') as f:  \n",
        "      f.write(r.content) \n",
        "  with fileinput.FileInput(\"yacht.txt\", inplace=True, backup='.bak') as file:\n",
        "    for line in file:\n",
        "        print(line.replace(\"  \", \" \"), end='')\n",
        "  ya = [str(i) for i in range(7)]        \n",
        "  yacht = pd.read_csv('yacht.txt', sep=\" \", names = ya, header=None)\n",
        "  print(\"Yacht dataset - {} examples - 7 columns\".format(len(yacht)))\n",
        "  print(\"Number of Nan :{}\".format(yacht.isna().sum().sum())) \n",
        "  return yacht, 7, \n",
        "\n",
        "def year_prediction():\n",
        "  year = [str(i) for i in range(90)]\n",
        "  year_prediction = pd.read_csv(year_prediction_url, sep=\" \", names = year, header=None)\n",
        "  print(\"Year_prediction_msd dataset - {} examples - 90 columns\".format(len(year_prediction)))\n",
        "  print(\"Number of Nan :{}\".format(year_prediction.isna().sum().sum())) \n",
        "  return year_prediction, 90\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOAF1w-iuUYf",
        "colab_type": "text"
      },
      "source": [
        "Here you can select the dataset you want to load in by selecting the appropriate function. The rest of the code is going to split a training and test set, and then put the data in cuda tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFUCIeaBOBHW",
        "colab_type": "code",
        "outputId": "25979dcc-443d-4b9a-9d25-bee38f2ade6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "## Loading data: the interface is simple, every dataset can be load and preprocessed by calling the function\n",
        "# with its name .\n",
        "\n",
        "# 1 - Call the dataset you want, this is the only thing you need to choose\n",
        "data, nb_features = yacht()\n",
        "\n",
        "\n",
        "# 2 - Preprocessing stuff ...\n",
        "nb_features = nb_features-1\n",
        "col = str(nb_features) \n",
        "x = data.drop(col, axis=1)\n",
        "y = data[col]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "\n",
        "x_train = np.array(x_train, dtype='float32')\n",
        "y_train = np.array(y_train, dtype='float32')\n",
        "x_test = np.array(x_test, dtype='float32')\n",
        "y_test = np.array(y_test, dtype='float32')\n",
        "\n",
        "x_train_tensor = torch.tensor(np.array(x_train),device = device)\n",
        "y_train_tensor = torch.tensor(np.array(y_train),device = device)\n",
        "x_test_tensor = torch.tensor(np.array(x_test),device = device)\n",
        "y_test_tensor = torch.tensor(np.array(y_test),device = device)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yacht dataset - 308 examples - 7 columns\n",
            "Number of Nan :0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFO00T6jubuS",
        "colab_type": "text"
      },
      "source": [
        "#Model Definition\n",
        "We define a 3 hidden layer neural net using the Scaled Exponential Linear Unit  activation function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eBDo2nLOMXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(NN, self).__init__()\n",
        "        self.L1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.L2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.L3 = nn.Linear(hidden_dim, output_dim,bias=False)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        # return x.w + b\n",
        "        h1 = F.elu(self.L1(x)) \n",
        "        h2 = F.elu(self.L2(h1))\n",
        "        out = self.L3(h2)        \n",
        "        return out\n",
        "        \n",
        "hidden_dim = 100     \n",
        "pyro.clear_param_store()\n",
        "neural_net = NN(nb_features,hidden_dim,1).cuda()   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op_wErfSuq51",
        "colab_type": "text"
      },
      "source": [
        "Now we define the model and the guide for variational inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blnjsk0oOZZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############### BAYESIAN LINEAR REGRESSION ############### \n",
        "\n",
        "\n",
        "\n",
        "def model(x_data, y_data, pi, sigma1, sigma2):\n",
        "    # Prior distributions\n",
        "    # Setting up the fixed parameter in our scaled mixture of gaussian\n",
        "    pi = .5\n",
        "    sigma1 = 1\n",
        "    sigma2 = np.exp(-6)\n",
        "\n",
        "    components_logits = torch.tensor([pi,1-pi], device=device)\n",
        "    component_scale = torch.tensor([sigma1,sigma2], device=device)\n",
        "\n",
        "    # 1st layer weight\n",
        "    loc_features_w1 = torch.zeros(2,nb_features,device=device)\n",
        "    coord_scale_w1 = torch.cat((torch.ones(1,nb_features,device=device) * sigma1,torch.ones(1,nb_features,device=device) * sigma2),0)\n",
        "    scale_gaussian_w1 = MixtureOfDiagNormals(loc_features_w1, coord_scale_w1, components_logits).expand([hidden_dim]).to_event(1)  \n",
        "    \n",
        "#    # 1st layer bias\n",
        "    loc_features_b1 = torch.zeros(2,hidden_dim,device=device)\n",
        "    coord_scale_b1 = torch.cat((torch.ones(1,hidden_dim,device=device) * sigma1,torch.ones(1,hidden_dim,device=device) * sigma2),0)\n",
        "    scale_gaussian_b1 = MixtureOfDiagNormals(loc_features_b1, coord_scale_b1, components_logits)  \n",
        "   \n",
        "    # 2nd layer weight\n",
        "    loc_features_w2 = torch.zeros(2,hidden_dim,device=device) \n",
        "    coord_scale_w2 = torch.cat((torch.ones(1,hidden_dim,device=device) * sigma1,torch.ones(1,hidden_dim,device=device) * sigma2),0)\n",
        "    scale_gaussian_w2 = MixtureOfDiagNormals(loc_features_w2, coord_scale_w2, components_logits).expand([hidden_dim]).to_event(1)\n",
        "    \n",
        "    # 2nd layer bias\n",
        "    loc_features_b2 = torch.zeros(2,hidden_dim,device=device)\n",
        "    coord_scale_b2 = torch.cat((torch.ones(1,hidden_dim,device=device) * sigma1,torch.ones(1,hidden_dim,device=device) * sigma2),0)\n",
        "    scale_gaussian_b2 = MixtureOfDiagNormals(loc_features_b2, coord_scale_b2, components_logits)  \n",
        "#\n",
        "##    # 3rd layer weight\n",
        "    loc_features_w3 = torch.zeros(2,hidden_dim,device=device)\n",
        "    coord_scale_w3 = torch.cat((torch.ones(1,hidden_dim,device=device) * sigma1,torch.ones(1,hidden_dim,device=device) * sigma2),0)\n",
        "    scale_gaussian_w3 = MixtureOfDiagNormals(loc_features_w3, coord_scale_w3, components_logits).expand([1]).to_event(1)\n",
        "\n",
        "    priors = {'L1.weight': scale_gaussian_w1, 'L1.bias': scale_gaussian_b1,\n",
        "              'L2.weight' :scale_gaussian_w2, 'L2.bias':scale_gaussian_b2,\n",
        "              'L3.weight': scale_gaussian_w3}\n",
        "    \n",
        "    lifted_module = pyro.random_module(\"module\", neural_net, priors)\n",
        "    # sample a nn (which also samples w and b)\n",
        "    lifted_reg_model = lifted_module()\n",
        "    # Assigning priors to weights\n",
        "    with pyro.plate(\"map\", size=len(x_data)):\n",
        "        # run the nn forward on data\n",
        "        prediction_mean = lifted_reg_model(x_data).squeeze(-1)\n",
        "        # condition on the observed data\n",
        "        pyro.sample(\"obs\",\n",
        "                    Normal(prediction_mean, 1),\n",
        "                    obs=y_data)\n",
        "        return prediction_mean\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgIAyY4pxc0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def guide(x_data, y_data):\n",
        "    # Variational posterior approximation\n",
        "    # Layer 1 weight\n",
        "    w1_mu = pyro.param(\"w1_mu\", torch.rand(hidden_dim, nb_features,device=device))\n",
        "    w1_sigma = pyro.param(\"w1_sigma\", torch.rand(hidden_dim,nb_features,device=device),constraint=constraints.positive)\n",
        "\n",
        "    # Layer 1 bias\n",
        "    b1_mu = pyro.param(\"b1_mu\", torch.rand(hidden_dim,device=device))\n",
        "    b1_sigma = pyro.param(\"b1_sigma\", torch.rand(hidden_dim,device=device), constraint=constraints.positive)\n",
        "    \n",
        "    # Layer 2 weight\n",
        "    w2_mu = pyro.param(\"w2_mu\", torch.rand(hidden_dim,hidden_dim,device=device))\n",
        "    w2_sigma = pyro.param(\"w2_sigma\", torch.rand(hidden_dim,hidden_dim,device=device), constraint=constraints.positive)\n",
        "    \n",
        "    # Layer 2 bias\n",
        "    b2_mu = pyro.param(\"b2_mu\", torch.rand(hidden_dim,device=device))\n",
        "    b2_sigma = pyro.param(\"b2_sigma\", torch.rand(hidden_dim,device=device), constraint=constraints.positive)\n",
        "\n",
        "#    # Layer 3 weight\n",
        "    w3_mu = pyro.param(\"w3_mu\", torch.rand(1, hidden_dim,device=device))\n",
        "    w3_sigma = pyro.param(\"w3_sigma\", torch.rand(1,hidden_dim,device=device), constraint=constraints.positive)\n",
        "    \n",
        "    # Latent variables\n",
        "    w1 = Normal(w1_mu, w1_sigma).to_event(2)   \n",
        "    b1 = Normal(b1_mu, b1_sigma).to_event(1)    \n",
        "    w2 = Normal(w2_mu, w2_sigma).to_event(2)    \n",
        "    b2 = Normal(b2_mu, b2_sigma).to_event(1)    \n",
        "    w3 = Normal(w3_mu, w3_sigma).to_event(2)   \n",
        "    \n",
        "    params = {'L1.weight': w1, 'L1.bias': b1,\n",
        "              'L2.weight' :w2, 'L2.bias':b2,\n",
        "              'L3.weight': w3}\n",
        "    # overloading the parameters in the module with random samples from the guide distributions\n",
        "    lifted_module = pyro.random_module(\"module\", neural_net, params)\n",
        "    # sample a regressor\n",
        "    return lifted_module()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3yBE_oFwAHk",
        "colab_type": "text"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6cJUvL_PKxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam({\"lr\": 0.005})\n",
        "svi = SVI(model, guide, optimizer, loss=Trace_ELBO(), num_samples=100)\n",
        "pyro.clear_param_store()\n",
        "\n",
        "\n",
        "num_iterations = 35000\n",
        "losses = []\n",
        "batch_size = len(x_train_tensor)\n",
        "def train(num_iterations):\n",
        "    pyro.clear_param_store()\n",
        "    for j in range(num_iterations):\n",
        "        # calculate the loss and take a gradient step\n",
        "        loss = svi.step(x_train_tensor, y_train_tensor)\n",
        "        losses.append(loss)\n",
        "        if j % 500 == 0:\n",
        "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / batch_size))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3U3jSMjQI7c",
        "colab_type": "code",
        "outputId": "cf951223-44b8-4524-c34b-6bbb781a3b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "train(num_iterations)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[iteration 0001] loss: 102734294.1722\n",
            "[iteration 0501] loss: 542001.5828\n",
            "[iteration 1001] loss: 48020.6799\n",
            "[iteration 1501] loss: 3978.6735\n",
            "[iteration 2001] loss: 60803.9944\n",
            "[iteration 2501] loss: 1748.4143\n",
            "[iteration 3001] loss: 841.4490\n",
            "[iteration 3501] loss: 2601.8685\n",
            "[iteration 4001] loss: 3028.1596\n",
            "[iteration 4501] loss: 337.0182\n",
            "[iteration 5001] loss: 327.6658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5L1Rtv3qPt3",
        "colab_type": "code",
        "outputId": "c71bd5f3-a352-4937-fd12-82a43809947a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "\n",
        "cost = np.array(losses[15000:])    \n",
        "t = np.arange(num_iterations-15000)\n",
        "plt.plot(t,cost)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f18d0f87518>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEDCAYAAADOc0QpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxFJIIW7iEgCKdxFRBJI4S4ikkD/HwLnsmiRjIcfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWFotY0yQ_0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility functions\n",
        "get_marginal = lambda traces, sites:EmpiricalMarginal(traces, sites)._get_samples_and_weights()[0].detach().cpu().numpy()\n",
        "\n",
        "def picp(y, y_lower, y_upper):\n",
        "    batch_size = len(y)\n",
        "    k = np.zeros(batch_size)\n",
        "    for i in range(batch_size):\n",
        "        k[i] = y_lower[i] <= y[i] <= y_upper[i]\n",
        "    return np.mean(k)\n",
        "\n",
        "def mpiw(y_lower, y_upper):\n",
        "    return np.mean(y_upper-y_lower)\n",
        "\n",
        "def wrapped_model(x_data, y_data):\n",
        "    pyro.sample(\"prediction\", Delta(model(x_data, y_data)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL5wgm88ScW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluating the test set\n",
        "    \n",
        "posterior = svi.run(x_test_tensor, y_test_tensor)\n",
        "\n",
        "trace_pred = TracePredictive(wrapped_model,\n",
        "                             posterior,\n",
        "                             num_samples=1000)\n",
        "\n",
        "\n",
        "post_pred_test = trace_pred.run(x_test_tensor, None)\n",
        "marginal_test = get_marginal(post_pred_test, sites= ['prediction', 'obs'])\n",
        "sampled_prediction_test = marginal_test[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVlgIXswTELz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Split the evaluations\n",
        "marginal_site = pd.DataFrame(sampled_prediction_test).transpose()\n",
        "describe = partial(pd.Series.describe, percentiles=[.025, 0.5, 0.975])\n",
        "summary = marginal_site.apply(describe, axis=1)[[\"mean\", \"std\", \"2.5%\", \"50%\", \"97.5%\"]]\n",
        "\n",
        "y_test_lower = np.array(summary['2.5%'])\n",
        "y_test_upper = np.array(summary['97.5%'])\n",
        "y_test_mean =  np.array(summary['mean'])\n",
        "\n",
        "proba_coverage_test = picp(y_test, y_test_lower, y_test_upper)\n",
        "interval_predicted_test = mpiw(y_test_lower, y_test_upper)\n",
        "rmse_test = np.mean(np.sqrt(np.power((y_test_mean-y_test),2)))\n",
        "\n",
        "interval_def = np.max(y) - np.min(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFjGUHVLg0kQ",
        "colab_type": "code",
        "outputId": "599c846a-9a4e-4162-c29f-97bbde364586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(\"Yacht\")\n",
        "print(\"Prediction Interval Coverage Probability (PICP): {}\".format(proba_coverage_test))\n",
        "print(\"Mean Prediction Interval Width (MPIW): {}\".format(interval_predicted_test))\n",
        "print(\"Natural Interval Width of Data: {}\".format(interval_def))\n",
        "print(\"Root Mean Square Error (RMSE): {}\".format(rmse_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wine\n",
            "Prediction Interval Coverage Probability (PICP): 1.0\n",
            "Mean Prediction Interval Width (MPIW): 8.55914637217298\n",
            "Natural Interval Width of Data: 5\n",
            "Root Mean Square Error (RMSE): 0.6825891375541687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGR9DN_miBun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}